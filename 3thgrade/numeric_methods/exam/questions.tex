\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{hyperref}
\usepackage{tabularx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[russian]{babel}
\usepackage[left=2cm,right=1cm,top=2cm,bottom=2cm]{geometry} % Устанавливаем поля

\begin{document}
\tableofcontents

\section{Конечномерные нормированные векторные пространства}

\subsection{Аксиомы нормы}
\subsection{Энергетическая норма}
\subsection{Эквивалентность векторных норм}

\section{Примеры норм матриц и их свойства}

\subsection{Матричные нормы, подчиненные кубической, октаэдрической, евклидовой (спектральная)}
\subsection{Связь между матричными нормами и спектральным радиусом матрицы}

\section{Сходимость последовательностей и рядов}

\subsection{Определение сходимости}

Пусть дана последовательность векторов \( \{\mathbf{x}^{(k)}\}_{k=1}^{\infty} \) в нормированном пространстве \( X \). Говорят, что последовательность \( \{\mathbf{x}^{(k)}\} \) сходится к вектору \( \mathbf{x} \in X \), если для любого \( \varepsilon > 0 \) существует номер \( N \), такой что для всех \( k \geq N \) выполняется неравенство \( \|\mathbf{x}^{(k)} - \mathbf{x}\| < \varepsilon \).

\subsection{Сходимость последовательности степеней матрицы и геометрической прогрессии матриц}

Рассмотрим последовательность матриц \( \{A^k\}_{k=1}^{\infty} \), где \( A \) — данная матрица. Говорят, что последовательность \( \{A^k\} \) сходится к матрице \( A^* \), если для любого \( \varepsilon > 0 \) существует номер \( N \), такой что для всех \( k \geq N \) выполняется неравенство \( \|A^k - A^*\| < \varepsilon \). Аналогично определяется сходимость геометрической прогрессии матриц.

\subsection{Необходимые и достаточные условия сходимости}

Необходимое условие сходимости последовательности векторов (матриц) в нормированном пространстве — это фундаментальность последовательности, т.е. для любого \( \varepsilon > 0 \) существует номер \( N \), такой что для всех \( k, m \geq N \) выполняется неравенство \( \|\mathbf{x}^{(k)} - \mathbf{x}^{(m)}\| < \varepsilon \).

Достаточное условие сходимости последовательности векторов (матриц) — это сходимость к пределу, как определено в соответствующем пункте.

\subsection{Достаточные условия сходимости}

Достаточные условия сходимости последовательности векторов (матриц) зависят от контекста и используемой теоремы. Например, для числовой последовательности достаточным условием сходимости является монотонность и ограниченность последовательности.


\section{Оценка собственных значений матриц}

\subsection{Критерии положительной определенности матрицы}
\subsection{Теорема Таусски}

Пусть \( A \) — эрмитова матрица (это матрица, равная своему сопряжённому транспонированному), и пусть \( \lambda_1, \lambda_2, \ldots, \lambda_n \) — её собственные значения, упорядоченные по убыванию модуля. Тогда для любого числа \( k \), такого что \( 1 \leq k \leq n \), выполняется

\[
\lambda_k \geq \frac{1}{k} \sum_{i=1}^k |\lambda_i|.
\]

Эта теорема дает оценку каждого собственного значения матрицы \( A \) через сумму модулей первых \( k \) собственных значений.

\section{Погрешности вычислений с плавающей точкой}

Погрешности вычислений с плавающей точкой являются неизбежными в численных методах из-за ограниченной точности представления действительных чисел в компьютерах.

\subsection{Прямой и обратный анализ ошибок}

Прямой анализ ошибок позволяет оценить ошибки, которые накапливаются в результате последовательности арифметических операций в конкретной численной задаче. Обратный анализ ошибок позволяет определить, какие исходные данные могут привести к заданным ошибкам в решении задачи.

\subsection{Обратный анализ ошибок решения СЛАУ}

Обратный анализ ошибок решения систем линейных алгебраических уравнений (СЛАУ) помогает определить, какие погрешности в правых частях и коэффициентах уравнений приведут к определенным погрешностям в решении.

\subsection{Число обусловленности матрицы}

Число обусловленности матрицы является мерой её чувствительности к изменениям входных данных. Оно определяет, насколько сильно могут измениться решения системы линейных уравнений при небольших изменениях в правых частях или коэффициентах матрицы.


\section{Прямые методы решения СЛАУ}

\subsection{Методы разложения квадратных матриц на треугольную и ортогональную}

Методы разложения квадратных матриц позволяют представить исходную матрицу в виде произведения треугольной и (или) ортогональной матрицы.

\begin{itemize}
  \item \textbf{LU-разложение}: Метод разложения матрицы \( A \) на произведение нижней треугольной \( L \) и верхней треугольной \( U \) матрицы, так что \( A = LU \).
  
  \item \textbf{QR-разложение}: Метод разложения матрицы \( A \) на произведение ортогональной \( Q \) и верхней треугольной \( R \) матрицы, так что \( A = QR \).
\end{itemize}

\subsection{Методы отражения и вращения для решения СЛАУ, нахождения обратной матрицы}

Методы отражения и вращения являются эффективными способами для решения систем линейных алгебраических уравнений (СЛАУ) и нахождения обратной матрицы.

\begin{itemize}
  \item \textbf{Метод отражений (метод Хаусхолдера)}: Используется для приведения матрицы к верхне-гессенберговой форме и решения СЛАУ.
  
  \item \textbf{Метод вращений (метод Якоби)}: Применяется для нахождения собственных значений и векторов симметричных матриц.
\end{itemize}

\subsection{Стратегии с перестановками строк (столбцов)}

Перестановки строк (или столбцов) матрицы часто используются для улучшения сходимости и устойчивости прямых методов решения СЛАУ.

\section{Условия применимости метода и стратегии перестановок}

\subsection{Необходимость перестановок}

Необходимость перестановок строк (столбцов) возникает при наличии нулевых или малых элементов на главной диагонали матрицы, что может приводить к численной неустойчивости методов.

\subsection{Стратегии перестановок}

\begin{itemize}
  \item \textbf{Частичная выборка}: Перестановка только некоторых строк (или столбцов) матрицы для улучшения устойчивости.
  
  \item \textbf{Полная перестановка (перемешивание)}: Перестановка всех строк (или столбцов) матрицы для максимального улучшения условий применимости метода.
\end{itemize}


\section{Метод прогонки}

\subsection{Условия осуществимости}
\subsection{Устойчивость прогонки}

\section{Метод простой итерации}

\subsection{Необходимые и достаточные условия сходимости}

\section{Стационарные итерационные методы}

\subsection{Стационарный метод Ричардсона, условия сходимости, оптимизация выбора параметра}
\subsubsection{Метод Гаусса-Зейделя}

Метод Гаусса-Зейделя является итерационным методом решения систем линейных уравнений, который осуществляет последовательное уточнение приближенного решения.

\begin{itemize}
  \item \textbf{Описание метода}: На каждой итерации \( k \) метода Гаусса-Зейделя значения переменных обновляются по одной, начиная с первой, и используются уже обновленные значения переменных.
  
  \item \textbf{Формула итерации}:
  \[
  x_i^{(k+1)} = \frac{1}{a_{ii}} \left( b_i - \sum_{j=1}^{i-1} a_{ij} x_j^{(k+1)} - \sum_{j=i+1}^{n} a_{ij} x_j^{(k)} \right), \quad i = 1, \ldots, n
  \]
  Здесь \( x_i^{(k)} \) обозначает \( i \)-ую компоненту вектора приближенного решения на \( k \)-й итерации, \( a_{ij} \) — элементы матрицы коэффициентов системы, а \( b_i \) — правые части уравнений.
\end{itemize}

\subsubsection{Верхняя релаксация}

Верхняя релаксация является модификацией метода Гаусса-Зейделя, в которой добавляется параметр релаксации \( \omega \), позволяющий ускорить сходимость метода.

\begin{itemize}
  \item \textbf{Формула итерации}:
  \[
  x_i^{(k+1)} = (1-\omega) x_i^{(k)} + \frac{\omega}{a_{ii}} \left( b_i - \sum_{j=1}^{i-1} a_{ij} x_j^{(k+1)} - \sum_{j=i+1}^{n} a_{ij} x_j^{(k)} \right), \quad i = 1, \ldots, n
  \]
  где \( \omega \) — параметр релаксации (\( 0 < \omega < 2 \)).
\end{itemize}

\subsubsection{Нижняя релаксация}

Нижняя релаксация также является модификацией метода Гаусса-Зейделя, но в отличие от верхней релаксации параметр \( \omega \) находится в интервале \( 0 < \omega < 1 \).

\begin{itemize}
  \item \textbf{Формула итерации}:
  \[
  x_i^{(k+1)} = (1-\omega) x_i^{(k)} + \frac{\omega}{a_{ii}} \left( b_i - \sum_{j=1}^{i-1} a_{ij} x_j^{(k+1)} - \sum_{j=i+1}^{n} a_{ij} x_j^{(k)} \right), \quad i = 1, \ldots, n
  \]
  где \( \omega \) — параметр релаксации (\( 0 < \omega < 1 \)).
\end{itemize}

\subsubsection{Условия сходимости}

\begin{itemize}
  \item \textbf{Метод Гаусса-Зейделя}: Сходимость метода Гаусса-Зейделя гарантируется, если матрица системы является строго диагонально доминируемой или симметричной и положительно определённой.
  
  \item \textbf{Верхняя и нижняя релаксации}: Для сходимости методов с релаксацией параметр \( \omega \) должен лежать в определённых интервалах (от \( 0 \) до \( 2 \) для верхней релаксации и от \( 0 \) до \( 1 \) для нижней релаксации), а матрица системы должна быть строго диагонально доминируемой или симметричной и положительно определённой.
\end{itemize}

\section{Схемы расщепления}

\subsection{Примеры}
\subsection{Условия сходимости}

\section{Нестационарные итерационные методы вариационного типа}

\subsection{Сходимость}

\section{Проблема собственных значений}

\subsection{Некорректность задачи}
\subsection{Обратный анализ ошибки для матриц простой структуры, коэффициенты перекоса}

\section{Степенной метод}

\subsection{Поиск максимального по модулю собственного числа и соответствующего собственного вектора}
\subsection{Скорость сходимости}
\subsection{Степенной метод со сдвигом}
\subsection{Метод обратных итераций}

\section{Итерационный метод вращений}

Итерационный метод вращений (или метод Якоби) представляет собой итерационный численный метод для нахождения собственных значений и собственных векторов симметричной матрицы.

\subsection{Нахождение собственных чисел}

Метод вращений используется для диагонализации симметричной матрицы. Основная идея заключается в последовательном применении элементарных вращений (плоских вращений вокруг элементарных плоскостей) для приближенного приведения матрицы к диагональному виду.

\begin{itemize}
  \item \textbf{Описание метода}: На каждом шаге выбирается пара элементов матрицы \( a_{ij} \) и \( a_{ji} \), которые необходимо занулить с помощью вращения. Это приводит к уточнению приближенных значений собственных чисел матрицы.
  
  \item \textbf{Сходимость}: Метод сходится к диагональной форме матрицы, где на диагонали стоят собственные значения.
\end{itemize}

\subsection{Стратегии выбора матриц вращения}

Для успешной работы метода вращений важно правильно выбирать матрицы вращения на каждом шаге итераций.

\begin{itemize}
  \item \textbf{Стратегии выбора}: Существует несколько стратегий выбора пар элементов для вращения:
    \begin{itemize}
      \item \textbf{Поиск максимального элемента}: Выбираются элементы с наибольшим абсолютным значением, чтобы максимально уменьшить их влияние на следующем шаге.
      \item \textbf{Поиск ненулевого элемента}: Выбираются первые ненулевые элементы в строке или столбце, чтобы ускорить процесс зануления элементов матрицы.
    \end{itemize}
\end{itemize}

\section{Почти треугольные матрицы (верхняя форма Хесенберга)}

Почти треугольная матрица (верхняя форма Хесенберга) представляет собой матрицу, у которой все элементы ниже первой субдиагонали равны нулю.

\begin{itemize}
  \item \textbf{Описание}: Почти треугольные матрицы имеют важные приложения в численных методах, таких как QR-разложение и решение систем линейных уравнений.
  \item \textbf{Свойства}: Характеризуются тем, что вычисления с ними могут быть эффективными благодаря структуре, близкой к треугольной.
\end{itemize}

\section{Нелинейные задачи}

\subsection{Метод простой итерации в полных метрических пространствах}

Метод простой итерации в полных метрических пространствах является одним из основных численных методов для решения нелинейных уравнений.

\begin{itemize}
  \item \textbf{Описание метода}: Метод простой итерации заключается в построении итерационной последовательности \( x_{n+1} = \varphi(x_n) \), которая сходится к решению уравнения \( F(x) = 0 \), где \( F \) — нелинейная функция.
  \item \textbf{Условия сходимости}: Для обеспечения сходимости метода простой итерации необходимо выполнение условий Липшица и сжимающего отображения.
\end{itemize}

\subsection{Теоремы о сжатых отображениях}

Теоремы о сжатых отображениях предоставляют условия на сжимающие отображения, при которых метод простой итерации обеспечивает сходимость к единственному решению нелинейного уравнения.

\begin{itemize}
  \item \textbf{Определение сжимающего отображения}: Отображение \( \varphi \) на метрическом пространстве \( (X, d) \) является сжимающим, если существует такая константа \( \alpha < 1 \), что для всех \( x, y \in X \) выполняется:
  \[
  d(\varphi(x), \varphi(y)) \leq \alpha d(x, y)
  \]
  \item \textbf{Теорема о сжатом отображении (Банаха)}: Если \( \varphi \) — сжимающее отображение на полном метрическом пространстве \( (X, d) \), то оно имеет единственную неподвижную точку \( x^* \), такую что \( \varphi(x^*) = x^* \). Кроме того, для любого начального приближения \( x_0 \in X \), итерационная последовательность \( \{x_n\} \) сходится к \( x^* \).
\end{itemize}

\subsection{Примеры}

Примеры использования метода простой итерации для решения нелинейных уравнений в различных областях науки и техники.

\section{Производная Фреше и метод Ньютона}

\subsection{Метод Ньютона в банаховых пространствах}

Метод Ньютона (или метод касательных) — это итерационный численный метод для решения систем нелинейных уравнений. В банаховых пространствах он обобщается на случай операторных уравнений.

\begin{itemize}
  \item \textbf{Описание метода}: На каждой итерации \( k \) метода Ньютона вычисляется следующее приближение \( x^{(k+1)} \) как решение линейной системы, которая приближает локальное поведение функции:
  \[
  F'(x^{(k)}) \cdot (x^{(k+1)} - x^{(k)}) = -F(x^{(k)})
  \]
  где \( F \) — вектор-функция, а \( F' \) — производная Фреше (якобиан).
  
  \item \textbf{Сходимость}: При достаточных условиях сходимости метод Ньютона обладает квадратичной сходимостью, что означает ускоренное приближение к решению.
\end{itemize}

\subsection{Достаточные условия квадратичной сходимости}

Для того чтобы метод Ньютона сходился к решению с квадратичной скоростью, необходимо выполнение следующих условий:

\begin{itemize}
  \item \textbf{Локальная обратимость}: Матрица \( F'(x^{*}) \), где \( x^{*} \) — точное решение, должна быть обратимой.
  \item \textbf{Липшицевость производной Фреше}: Существует константа \( L \), такая что для всех \( x \) в окрестности \( x^{*} \) выполняется:
  \[
  \| F'(x) - F'(x^{*}) \| \leq L \| x - x^{*} \|
  \]
\end{itemize}

\subsection{Примеры}

Примеры применения метода Ньютона в различных областях, таких как численное решение уравнений, оптимизация функций и моделирование физических систем.

\subsection{Модификации метода}

Метод Ньютона имеет несколько модификаций, направленных на улучшение сходимости или расширение применимости:

\begin{itemize}
  \item \textbf{Метод с демпфированием}: Используется для улучшения сходимости метода в случае наличия вырожденности в окрестности точки.
  \item \textbf{Гибридные методы}: Комбинируют метод Ньютона с другими численными методами для улучшения стабильности или скорости сходимости.
\end{itemize}
\end{document}
